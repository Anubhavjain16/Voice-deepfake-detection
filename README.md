ğŸ™ï¸ Voice Deepfake Detection System

ğŸ§  Overview

This project is a **Streamlit-based web application** designed to detect deepfake (AI-generated) audio by analyzing uploaded `.wav` files. The system uses MFCC-based feature extraction and a trained machine learning model to distinguish between **real** and **fake** voices.

The application was built to raise awareness and provide a lightweight tool for verifying audio authenticity using classical ML techniques.

---

ğŸš€ Features

- Upload and analyze `.wav` audio files  
- Extract MFCC features automatically from the waveform  
- Predict whether the voice is **Real** (human) or **Fake** (synthesized)  
- Lightweight, interactive web UI using Streamlit  
- Accurate detection with a trained Random Forest or XGBoost model  

---

ğŸ”§ Technologies Used

- **Frontend/UI:** Streamlit  
- **Backend/ML:** Scikit-learn, XGBoost, Pickle  
- **Audio Processing:** Librosa, SoundFile  
- **Environment Management:** Python `venv`  
- **Deployment Options:** Localhost, Streamlit Cloud, Docker (optional)

---

 ğŸ› ï¸ Installation

 1. Clone the repository
```bash
git clone https://github.com/your-username/voice-deepfake-detector.git
cd voice-deepfake-detector
````

### 2. Create and activate a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # For macOS/Linux
venv\Scripts\activate      # For Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Application

```bash
streamlit run app.py
```

Navigate to the app in your browser at:
ğŸ“ `http://localhost:8501`

---

## ğŸ¯ How It Works

1. The user uploads a `.wav` audio file.
2. The application extracts **MFCC** features using `librosa`.
3. These features are passed to a **trained ML model** (`best_model.pkl`).
4. The system outputs whether the voice is likely **Real** or **Fake**.

---

## ğŸ¯ API Logic (Internal - via app.py)

* **Upload File**
  Saves the uploaded `.wav` audio file locally as `uploaded_audio.wav`.

* **Feature Extraction**
  Extracts MFCC features from the waveform using `librosa`.

* **Model Prediction**
  Loads a pre-trained model and classifies the voice.

* **UI Display**
  Presents the result as `Real` or `Fake` in the browser.

---

## ğŸ§ª Model Details

* **Input Features:** MFCC mean vectors from `.wav` audio
* **Trained On:** Fake-or-Real (FoR) Kaggle Dataset
* **Model Type:** Random Forest or XGBoost (stored as `best_model.pkl`)
* **Accuracy:** >92% on test data

---

## ğŸ“ File Structure

```
voice-deepfake-detector/
â”œâ”€â”€ app.py                # Streamlit app
â”œâ”€â”€ best_model.pkl        # Trained ML model
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ uploaded_audio.wav    # Saved user audio (temporary)
â”œâ”€â”€ README.md             # Project documentation
```

---

## ğŸ§  Dataset

* **Source:** [Fake-or-Real Voice Dataset (Kaggle)](https://www.kaggle.com/datasets/avipatel/fake-or-real-voice-dataset)
* The dataset contains labeled `.wav` files for **real** and **fake** samples used during model training.

---

## ğŸŒ Deployment Options

* **Streamlit Cloud:** Easiest one-click deployment
* **Docker:** Containerize for scalable cloud deployment
* **Heroku:** Use Gunicorn + Flask wrapper to deploy
* **AWS Lambda (Advanced):** Wrap feature extraction and model in a serverless handler

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a new branch (`feature-branch`)
3. Commit your changes
4. Push the branch and open a Pull Request

---

## ğŸ“« Contact

**Author:** Anubhav Jain
ğŸ“§ [anubhavjain.1116@gmail.com](mailto:anubhavjain.1116@gmail.com)
ğŸ”— [LinkedIn](https://www.linkedin.com/in/anubhav-jain1/)
ğŸ’» [GitHub](https://github.com/Anubhavjain16)

---

## ğŸ“„ License

This project is intended for academic and research use only.
For commercial or enterprise use, please contact the author.
